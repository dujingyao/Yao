```python
import numpy as np
import pandas as pd
from scipy.optimize import differential_evolution
import matplotlib.pyplot as plt
from colormath.color_objects import sRGBColor, XYZColor, LabColor
from colormath.color_conversions import convert_color
class OptimizedFourToFiveChannelConverter:
    def __init__(self, excel_file_path='LEDæ•°æ®.xlsx'):
        self.excel_file = excel_file_path
        self.led_data = {}
        self.rgbv_data = None
        self.rgbcx_data = None
        self.conversion_matrix = None
        self.optimization_history = []
    def load_led_data(self):
        sheet_names = ['R_R', 'R_G', 'R_B', 'G_R', 'G_G', 'G_B', 'B_R', 'B_G', 'B_B']
        print("ğŸ“‚ æ­£åœ¨åŠ è½½LEDæ•°æ®...")
        for sheet in sheet_names:
            try:
                df = pd.read_excel(self.excel_file, sheet_name=sheet, header=None)
                self.led_data[sheet] = df.values
                print(f"âœ… æˆåŠŸåŠ è½½ {sheet}: {df.shape}")
            except Exception as e:
                print(f"âŒ åŠ è½½ {sheet} å¤±è´¥: {e}")
        return len(self.led_data) == 9

    def build_rgbv_channels(self):
        print("ğŸ”§ æ„å»ºRGBVå››é€šé“æ•°æ®...")
       
        R_channel = self.led_data['R_R']  # çº¢è‰²LEDçš„çº¢è‰²å“åº”
        G_channel = self.led_data['G_G']  # ç»¿è‰²LEDçš„ç»¿è‰²å“åº”  
        B_channel = self.led_data['B_B']  # è“è‰²LEDçš„è“è‰²å“åº”
        
        V_channel = (0.299 * self.led_data['R_R'] + 
                    0.587 * self.led_data['G_G'] + 
                    0.114 * self.led_data['B_B'])
        # ç»„åˆæˆRGBVæ•°ç»„
        height, width = R_channel.shape
        rgbv_array = np.zeros((height, width, 4))
        rgbv_array[:, :, 0] = R_channel
        rgbv_array[:, :, 1] = G_channel
        rgbv_array[:, :, 2] = B_channel
        rgbv_array[:, :, 3] = V_channel
        self.rgbv_data = rgbv_array
        print(f"âœ… RGBVæ•°æ®æ„å»ºå®Œæˆ: {rgbv_array.shape}")
        return rgbv_array
    
    def build_rgbcx_channels(self):
       
        print("ğŸ¯ æ„å»ºRGBCXäº”é€šé“ç›®æ ‡æ•°æ®...")
        
        # åŸºç¡€RGBé€šé“
        R_target = self.led_data['R_R']
        G_target = self.led_data['G_G'] 
        B_target = self.led_data['B_B']
       
        C_channel = 0.6 * self.led_data['G_B'] + 0.4 * self.led_data['B_G']
        
        X_channel = (0.2 * self.led_data['R_G'] + 
                    0.3 * self.led_data['G_R'] + 
                    0.3 * self.led_data['B_R'] +
                    0.2 * self.led_data['R_B'])
        
        height, width = R_target.shape
        rgbcx_array = np.zeros((height, width, 5))
        rgbcx_array[:, :, 0] = R_target
        rgbcx_array[:, :, 1] = G_target
        rgbcx_array[:, :, 2] = B_target
        rgbcx_array[:, :, 3] = C_channel
        rgbcx_array[:, :, 4] = X_channel
        
        self.rgbcx_data = rgbcx_array
        print(f"âœ… RGBCXæ•°æ®æ„å»ºå®Œæˆ: {rgbcx_array.shape}")
        
        return rgbcx_array
    
    def initialize_conversion_matrix(self):
       
        initial_matrix = np.array([
            [0.95, 0.0,  0.0,  0.3,  0.2],   # R â†’ RGBCX
            [0.0,  0.95, 0.0,  0.3,  0.1],   # G â†’ RGBCX  
            [0.0,  0.0,  0.95, 0.2,  0.1],   # B â†’ RGBCX
            [0.0,  0.0,  0.0,  0.6,  0.4]    # V â†’ CX
        ])
        
        self.conversion_matrix = initial_matrix
        return initial_matrix
    
    def rgb_to_xyz(self, rgb):
        if np.max(rgb) > 1:
            rgb = rgb / 255.0
        
        # ä¼½é©¬æ ¡æ­£
        def gamma_correct(channel):
            if channel <= 0.04045:
                return channel / 12.92
            else:
                return np.power((channel + 0.055) / 1.055, 2.4)
        
        rgb_linear = np.array([gamma_correct(c) for c in rgb])
        
        # sRGBåˆ°XYZè½¬æ¢çŸ©é˜µ
        M = np.array([
            [0.4124564, 0.3575761, 0.1804375],
            [0.2126729, 0.7151522, 0.0721750],
            [0.0193339, 0.1191920, 0.9503041]
        ])
        
        xyz = np.dot(M, rgb_linear) * 100
        return xyz
    
    def xyz_to_lab(self, xyz):
        # D65æ ‡å‡†å…‰æº
        xyz_n = np.array([95.047, 100.000, 108.883])
        xyz_norm = xyz / xyz_n
        
        def f_func(t):
            delta = 6/29
            if t > delta**3:
                return np.power(t, 1/3)
            else:
                return t / (3 * delta**2) + 4/29
        
        fx = f_func(xyz_norm[0])
        fy = f_func(xyz_norm[1])
        fz = f_func(xyz_norm[2])
        
        L = 116 * fy - 16
        a = 500 * (fx - fy)
        b = 200 * (fy - fz)
        
        return np.array([L, a, b])
    
    def calculate_delta_e(self, lab1, lab2):
        return np.sqrt(np.sum((lab1 - lab2)**2))
    
    def fitness_function(self, params):
        try:
            matrix_params = params[:20].reshape(4, 5)
            v_xyz_factors = params[20:23]
            cx_xyz_factors = params[23:29].reshape(2, 3)
            
            base_matrix = self.initialize_conversion_matrix()
            conversion_matrix = base_matrix + matrix_params * 0.1  # 10%çš„è°ƒæ•´å¹…åº¦
           
            conversion_matrix = np.clip(conversion_matrix, 0, 1.5)
          
            rgbv_flat = self.rgbv_data.reshape(-1, 4)
            predicted_rgbcx = np.dot(rgbv_flat, conversion_matrix)
            
            v_influence = rgbv_flat[:, 3:4] * v_xyz_factors.reshape(1, 3)
          
            predicted_rgbcx[:, 3] *= cx_xyz_factors[0, 0]  # Cé€šé“
            predicted_rgbcx[:, 4] *= cx_xyz_factors[1, 0]  # Xé€šé“
            
            predicted_rgbcx = predicted_rgbcx.reshape(self.rgbcx_data.shape)
            actual_rgbcx = self.rgbcx_data
         
            total_delta_e = 0
            valid_pixels = 0
            
            height, width, _ = predicted_rgbcx.shape
            for i in range(0, height, 4):  # é‡‡æ ·ä»¥æé«˜æ•ˆç‡
                for j in range(0, width, 4):
                    try:
                        pred_rgb = predicted_rgbcx[i, j, :3]
                        pred_xyz = self.rgb_to_xyz(pred_rgb)
                        pred_lab = self.xyz_to_lab(pred_xyz)
                    
                        actual_rgb = actual_rgbcx[i, j, :3]
                        actual_xyz = self.rgb_to_xyz(actual_rgb)
                        actual_lab = self.xyz_to_lab(actual_xyz)
                        
                        delta_e = self.calculate_delta_e(pred_lab, actual_lab)
                        total_delta_e += delta_e
                        valid_pixels += 1
                        
                    except:
                        continue
            
            if valid_pixels == 0:
                return 1000.0
            
            avg_delta_e = total_delta_e / valid_pixels
        
            matrix_penalty = np.sum(np.abs(matrix_params)) * 0.01
            
            fitness = avg_delta_e + matrix_penalty
           
            self.optimization_history.append(fitness)
            
            return fitness
            
        except Exception as e:
            return 1000.0  # è¿”å›å¤§å€¼è¡¨ç¤ºå¤±è´¥
    
    def pso_optimize(self, swarm_size=30, max_iterations=100, w=0.7, c1=1.5, c2=1.5):
        print(f"ğŸš€ å¼€å§‹PSOä¼˜åŒ– (ç²’å­æ•°: {swarm_size}, æœ€å¤§è¿­ä»£: {max_iterations})")

        n_params = 29
        bounds = []
        
        # è½¬æ¢çŸ©é˜µå‚æ•°è¾¹ç•Œ
        for i in range(20):
            bounds.append((-0.5, 0.5))
        
        # Vé€šé“XYZå› å­è¾¹ç•Œ
        for i in range(3):
            bounds.append((0.5, 1.5))
            
        # Cå’ŒXé€šé“å› å­è¾¹ç•Œ
        for i in range(6):
            bounds.append((0.5, 1.5))
        
        # åˆå§‹åŒ–ç²’å­ç¾¤
        particles = []
        velocities = []
        personal_best = []
        personal_best_fitness = []
        
        for _ in range(swarm_size):
            # éšæœºåˆå§‹åŒ–ç²’å­ä½ç½®
            particle = []
            velocity = []
            
            for low, high in bounds:
                particle.append(np.random.uniform(low, high))
                velocity.append(np.random.uniform(-0.1, 0.1))
            
            particles.append(np.array(particle))
            velocities.append(np.array(velocity))
            
            # è®¡ç®—åˆå§‹é€‚åº”åº¦
            fitness = self.fitness_function(particles[-1])
            personal_best.append(particles[-1].copy())
            personal_best_fitness.append(fitness)
        
        # æ‰¾åˆ°å…¨å±€æœ€ä¼˜
        global_best_idx = np.argmin(personal_best_fitness)
        global_best = personal_best[global_best_idx].copy()
        global_best_fitness = personal_best_fitness[global_best_idx]
        
        print(f"åˆå§‹æœ€ä¼˜é€‚åº”åº¦: {global_best_fitness:.4f}")
        
        # è¿­ä»£ä¼˜åŒ–
        stagnation_count = 0
        prev_best_fitness = global_best_fitness
        
        for iteration in range(max_iterations):
            improved = False
            
            for i in range(swarm_size):
                # æ›´æ–°é€Ÿåº¦
                r1, r2 = np.random.random(n_params), np.random.random(n_params)
                
                cognitive = c1 * r1 * (personal_best[i] - particles[i])
                social = c2 * r2 * (global_best - particles[i])
                
                velocities[i] = w * velocities[i] + cognitive + social
                
                velocities[i] = np.clip(velocities[i], -0.2, 0.2)
               
                particles[i] = particles[i] + velocities[i]
                
                for j, (low, high) in enumerate(bounds):
                    particles[i][j] = np.clip(particles[i][j], low, high)
             
                fitness = self.fitness_function(particles[i])
               
                if fitness < personal_best_fitness[i]:
                    personal_best[i] = particles[i].copy()
                    personal_best_fitness[i] = fitness
                    
                    if fitness < global_best_fitness:
                        global_best = particles[i].copy()
                        global_best_fitness = fitness
                        improved = True
            
            # æ—©åœæ£€æŸ¥
            if not improved:
                stagnation_count += 1
            else:
                stagnation_count = 0
            
            # æ¯10ä»£è¾“å‡ºè¿›åº¦
            if iteration % 10 == 0:
                avg_fitness = np.mean(personal_best_fitness)
                print(f"ç¬¬{iteration:3d}ä»£: æœ€ä½³={global_best_fitness:.2f}, "
                      f"å¹³å‡={avg_fitness:.2f}, åœæ»={stagnation_count}")
            
            # æ—©åœæ¡ä»¶
            if stagnation_count >= 30:
                print(f"æ—©åœï¼šè¿ç»­{stagnation_count}ä»£æ— æ”¹å–„")
                break
        
        print(f"âœ… PSOä¼˜åŒ–å®Œæˆï¼æœ€ç»ˆé€‚åº”åº¦: {global_best_fitness:.4f}")
        
        return global_best, global_best_fitness
    
    def apply_optimized_conversion(self, optimal_params):
    
        print("ğŸ”§ åº”ç”¨ä¼˜åŒ–è½¬æ¢å‚æ•°...")
        
        matrix_params = optimal_params[:20].reshape(4, 5)
        v_xyz_factors = optimal_params[20:23]
        cx_xyz_factors = optimal_params[23:29].reshape(2, 3)
        
        base_matrix = self.initialize_conversion_matrix()
        final_matrix = base_matrix + matrix_params * 0.1
        final_matrix = np.clip(final_matrix, 0, 1.5)
        
        rgbv_flat = self.rgbv_data.reshape(-1, 4)
        converted_rgbcx = np.dot(rgbv_flat, final_matrix)
        
        converted_rgbcx[:, 3] *= cx_xyz_factors[0, 0]  # Cé€šé“
        converted_rgbcx[:, 4] *= cx_xyz_factors[1, 0]  # Xé€šé“
        
        converted_rgbcx = converted_rgbcx.reshape(self.rgbcx_data.shape)
        
        self.conversion_matrix = final_matrix
        print("âœ… è½¬æ¢å®Œæˆï¼")
        
        return converted_rgbcx
    
    def comprehensive_optimization(self):
        
        print("ğŸ¯ å¼€å§‹æ‰§è¡Œå®Œæ•´ä¼˜åŒ–æµç¨‹...")
        
        if not self.load_led_data():
            return None
        
        self.build_rgbv_channels()
        self.build_rgbcx_channels()
        
        self.initialize_conversion_matrix()
        
        optimal_params, best_fitness = self.pso_optimize(
            swarm_size=30, 
            max_iterations=100
        )
        converted_data = self.apply_optimized_conversion(optimal_params)
        
        evaluation_results = self.evaluate_conversion_quality(converted_data)
        
        results = {
            'optimal_parameters': optimal_params,
            'best_fitness': best_fitness,
            'conversion_matrix': self.conversion_matrix,
            'converted_data': converted_data,
            'evaluation': evaluation_results,
            'optimization_history': self.optimization_history
        }
        
        print("ğŸ‰ å®Œæ•´ä¼˜åŒ–æµç¨‹æ‰§è¡Œå®Œæˆï¼")
        return results
    
    def evaluate_conversion_quality(self, converted_data):
        
        print("ğŸ“Š è¯„ä¼°è½¬æ¢è´¨é‡...")
        
        delta_e_values = []
        actual_data = self.rgbcx_data
        
        height, width, _ = converted_data.shape
        
        for i in range(0, height, 2):  # é‡‡æ ·è¯„ä¼°
            for j in range(0, width, 2):
                try:
                    conv_rgb = converted_data[i, j, :3]
                    conv_xyz = self.rgb_to_xyz(conv_rgb)
                    conv_lab = self.xyz_to_lab(conv_xyz)
                    
                    actual_rgb = actual_data[i, j, :3]
                    actual_xyz = self.rgb_to_xyz(actual_rgb)
                    actual_lab = self.xyz_to_lab(actual_xyz)
                    
                    delta_e = self.calculate_delta_e(conv_lab, actual_lab)
                    delta_e_values.append(delta_e)
                    
                except:
                    continue
        
        delta_e_values = np.array(delta_e_values)
        
        quality_metrics = {
            'mean_delta_e': np.mean(delta_e_values),
            'median_delta_e': np.median(delta_e_values),
            'std_delta_e': np.std(delta_e_values),
            'max_delta_e': np.max(delta_e_values),
            'min_delta_e': np.min(delta_e_values),
            'percentile_95': np.percentile(delta_e_values, 95),
            'excellent_ratio': np.sum(delta_e_values < 1.0) / len(delta_e_values),
            'good_ratio': np.sum(delta_e_values < 3.0) / len(delta_e_values),
            'acceptable_ratio': np.sum(delta_e_values < 6.0) / len(delta_e_values)
        }
        
        print(f"âœ… è´¨é‡è¯„ä¼°å®Œæˆ - å¹³å‡Î”E: {quality_metrics['mean_delta_e']:.4f}")
        
        return quality_metrics

if __name__ == "__main__":
   
    converter = OptimizedFourToFiveChannelConverter('LEDæ•°æ®.xlsx')
    
    results = converter.comprehensive_optimization()
    
    if results:
        print("\nğŸŠ ä¼˜åŒ–ç»“æœæ€»ç»“:")
        print(f"æœ€ä¼˜é€‚åº”åº¦: {results['best_fitness']:.4f}")
        print(f"å¹³å‡è‰²å·®: {results['evaluation']['mean_delta_e']:.4f}")
        print(f"ä¼˜ç§€çº§åˆ«æ¯”ä¾‹: {results['evaluation']['excellent_ratio']:.2%}")
        print(f"è‰¯å¥½çº§åˆ«æ¯”ä¾‹: {results['evaluation']['good_ratio']:.2%}")
```

## B.2 Vé€šé“åˆ†è§£ç®—æ³•

```python
def
    if method == 'adaptive':
  
        def calculate_adaptive_weights(rgb_pixel):
            """æ ¹æ®RGBæ¯”ä¾‹åŠ¨æ€è°ƒæ•´æƒé‡"""
            total = np.sum(rgb_pixel)
            if total == 0:
                return np.array([0.299, 0.587, 0.114])  # é»˜è®¤æƒé‡
            
            rgb_norm = rgb_pixel / total
            
            dominant_channel = np.argmax(rgb_norm)
            weights = np.array([0.299, 0.587, 0.114])
            
            weights[dominant_channel] *= 1.2
            weights = weights / np.sum(weights)  # é‡æ–°å½’ä¸€åŒ–
            
            return weights
        
        height, width, _ = rgb_data.shape
        v_channel = np.zeros((height, width))
        
        for i in range(height):
            for j in range(width):
                rgb_pixel = rgb_data[i, j]
                weights = calculate_adaptive_weights(rgb_pixel)
                v_channel[i, j] = np.dot(weights, rgb_pixel)
        
        return v_channel
    
    elif method == 'luminance':
        # æ ‡å‡†äº®åº¦åˆ†è§£
        luminance_weights = np.array([0.299, 0.587, 0.114])
        return np.dot(rgb_data, luminance_weights)
    
    elif method == 'contrast':
        contrast_weights = np.array([0.25, 0.50, 0.25])
        base_v = np.dot(rgb_data, contrast_weights)
        
        mean_v = np.mean(base_v)
        enhanced_v = mean_v + 1.2 * (base_v - mean_v)
        
        return np.clip(enhanced_v, 0, 255)

def v_channel_quality_assessment(v_channel, rgb_original):
    
    rgb_luminance = 0.299 * rgb_original[:,:,0] + 0.587 * rgb_original[:,:,1] + 0.114 * rgb_original[:,:,2]
    correlation = np.corrcoef(v_channel.flatten(), rgb_luminance.flatten())[0,1]
    
    def calculate_entropy(data):
        hist, _ = np.histogram(data.flatten(), bins=256, range=(0, 255))
        hist = hist / np.sum(hist)
        hist = hist[hist > 0]  # ç§»é™¤é›¶å€¼
        entropy = -np.sum(hist * np.log2(hist))
        return entropy
    
    v_entropy = calculate_entropy(v_channel)
    rgb_entropy = np.mean([calculate_entropy(rgb_original[:,:,i]) for i in range(3)])
    
    v_range = np.max(v_channel) - np.min(v_channel)
    rgb_range = np.mean([np.max(rgb_original[:,:,i]) - np.min(rgb_original[:,:,i]) for i in range(3)])
    
    quality_metrics = {
        'luminance_correlation': correlation,
        'entropy_ratio': v_entropy / rgb_entropy,
        'dynamic_range_ratio': v_range / rgb_range,
        'uniformity_index': 1 / (1 + np.std(v_channel) / np.mean(v_channel))
    }
    
    return quality_metrics
```

## B.3 å·®åˆ†è¿›åŒ–ä¼˜åŒ–å™¨

```python
class DifferentialEvolutionOptimizer:
   
    def __init__(self, converter):
        self.converter = converter
        
    def optimize(self, bounds, population_size=50, max_generations=200, F=0.5, CR=0.7):
       
        print(f"ğŸ§¬ å¼€å§‹å·®åˆ†è¿›åŒ–ä¼˜åŒ– (ç§ç¾¤: {population_size}, ä»£æ•°: {max_generations})")
        
        n_params = len(bounds)
        
        population = []
        fitness_values = []
        
        for _ in range(population_size):
            individual = []
            for low, high in bounds:
                individual.append(np.random.uniform(low, high))
            
            individual = np.array(individual)
            population.append(individual)
            
            fitness = self.converter.fitness_function(individual)
            fitness_values.append(fitness)
        
        population = np.array(population)
        fitness_values = np.array(fitness_values)
        
        best_idx = np.argmin(fitness_values)
        best_individual = population[best_idx].copy()
        best_fitness = fitness_values[best_idx]
        
        print(f"åˆå§‹æœ€ä¼˜é€‚åº”åº¦: {best_fitness:.4f}")
        
        for generation in range(max_generations):
            new_population = []
            new_fitness = []
            
            for i in range(population_size):
                # é€‰æ‹©ä¸‰ä¸ªä¸åŒçš„ä¸ªä½“è¿›è¡Œå˜å¼‚
                candidates = list(range(population_size))
                candidates.remove(i)
                a, b, c = np.random.choice(candidates, 3, replace=False)
                
                mutant = population[a] + F * (population[b] - population[c])
                
                for j, (low, high) in enumerate(bounds):
                    mutant[j] = np.clip(mutant[j], low, high)
                
                trial = population[i].copy()
                crossover_points = np.random.random(n_params) < CR
                trial[crossover_points] = mutant[crossover_points]
                
                if not np.any(crossover_points):
                    j = np.random.randint(n_params)
                    trial[j] = mutant[j]
                
                trial_fitness = self.converter.fitness_function(trial)
                
                if trial_fitness < fitness_values[i]:
                    new_population.append(trial)
                    new_fitness.append(trial_fitness)
                    
                    if trial_fitness < best_fitness:
                        best_individual = trial.copy()
                        best_fitness = trial_fitness
                else:
                    new_population.append(population[i])
                    new_fitness.append(fitness_values[i])
            
            population = np.array(new_population)
            fitness_values = np.array(new_fitness)
            
            if generation % 20 == 0:
                avg_fitness = np.mean(fitness_values)
                print(f"ç¬¬{generation:3d}ä»£: æœ€ä½³={best_fitness:.4f}, å¹³å‡={avg_fitness:.4f}")
        
        print(f"âœ… å·®åˆ†è¿›åŒ–å®Œæˆï¼æœ€ç»ˆé€‚åº”åº¦: {best_fitness:.4f}")
        return best_individual, best_fitness

def advanced_gamut_mapping(source_channels, target_channels):
   
    def calculate_gamut_boundary(channels):
        xy_points = []
        for i in range(0, channels.shape[0], 10):  # é‡‡æ ·
            for j in range(0, channels.shape[1], 10):
                rgb = channels[i, j, :3]
                if np.sum(rgb) > 10:  # å¿½ç•¥æš—åƒç´ 
                    # è½¬æ¢åˆ°XYZ
                    xyz = rgb_to_xyz_simple(rgb)
                    if np.sum(xyz) > 0:
                        x = xyz[0] / np.sum(xyz)
                        y = xyz[1] / np.sum(xyz)
                        xy_points.append([x, y])
        
        return np.array(xy_points)
    
    def rgb_to_xyz_simple(rgb):
        rgb_norm = rgb / 255.0
        M = np.array([
            [0.4124, 0.3576, 0.1805],
            [0.2126, 0.7152, 0.0722],
            [0.0193, 0.1192, 0.9503]
        ])
        return np.dot(M, rgb_norm)
    
    source_gamut = calculate_gamut_boundary(source_channels)
    target_gamut = calculate_gamut_boundary(target_channels)
    
    if len(source_gamut) == 0 or len(target_gamut) == 0:
        return target_channels  # å¦‚æœæ— æ³•è®¡ç®—è‰²åŸŸï¼Œè¿”å›åŸå§‹ç›®æ ‡
    
    source_center = np.mean(source_gamut, axis=0)
    target_center = np.mean(target_gamut, axis=0)
    
    source_extent = np.max(source_gamut, axis=0) - np.min(source_gamut, axis=0)
    target_extent = np.max(target_gamut, axis=0) - np.min(target_gamut, axis=0)
    
    scale_factors = target_extent / (source_extent + 1e-8)
    translation = target_center - source_center * scale_factors
    
    mapped_channels = target_channels.copy()
    
    for i in range(3):
        channel_mean = np.mean(source_channels[:, :, i])
        target_mean = np.mean(target_channels[:, :, i])
        if channel_mean > 0:
            adjustment_factor = target_mean / channel_mean
            mapped_channels[:, :, i] = source_channels[:, :, i] * adjustment_factor
    
    return mapped_channels
```

## B.4 ç®—æ³•æ€§èƒ½è¯„ä¼°

```python
def evaluate_pso_performance(optimization_history, evaluation_results):
    """
    è¯„ä¼°PSOç®—æ³•æ€§èƒ½
    
    å‚æ•°:
        optimization_history: PSOä¼˜åŒ–å†å²è®°å½•
        evaluation_results: è½¬æ¢è´¨é‡è¯„ä¼°ç»“æœ
    
    è¿”å›:
        PSOæ€§èƒ½è¯„ä¼°æŠ¥å‘Š
    """
    performance_metrics = {
        'convergence_analysis': {},
        'optimization_efficiency': {},
        'quality_assessment': {}
    }
    
    # æ”¶æ•›åˆ†æ
    if optimization_history:
        initial_fitness = optimization_history[0]
        final_fitness = optimization_history[-1]
        improvement_ratio = (initial_fitness - final_fitness) / initial_fitness
        
        # è®¡ç®—æ”¶æ•›é€Ÿåº¦
        half_improvement = initial_fitness - (initial_fitness - final_fitness) / 2
        convergence_generation = 0
        for i, fitness in enumerate(optimization_history):
            if fitness <= half_improvement:
                convergence_generation = i
                break
        
        performance_metrics['convergence_analysis'] = {
            'initial_fitness': initial_fitness,
            'final_fitness': final_fitness,
            'improvement_ratio': improvement_ratio,
            'convergence_speed': convergence_generation,
            'total_generations': len(optimization_history),
            'convergence_stability': np.std(optimization_history[-20:]) if len(optimization_history) >= 20 else 0
        }
    
    # ä¼˜åŒ–æ•ˆç‡
    performance_metrics['optimization_efficiency'] = {
        'parameter_space_dimension': 29,
        'exploration_effectiveness': improvement_ratio > 0.5,
        'exploitation_balance': np.std(optimization_history) / np.mean(optimization_history) if optimization_history else 0
    }
    
    # è´¨é‡è¯„ä¼°æ•´åˆ
    if evaluation_results:
        performance_metrics['quality_assessment'] = {
            'color_accuracy': evaluation_results.get('mean_delta_e', 0),
            'consistency': 1 / (1 + evaluation_results.get('std_delta_e', 1)),
            'excellent_coverage': evaluation_results.get('excellent_ratio', 0),
            'overall_grade': 'A' if evaluation_results.get('excellent_ratio', 0) > 0.8 else 
                           'B' if evaluation_results.get('good_ratio', 0) > 0.9 else 'C'
        }
    
    return performance_metrics

def calculate_conversion_matrix_properties(conversion_matrix):
    """
    è®¡ç®—è½¬æ¢çŸ©é˜µçš„æ•°å­¦æ€§è´¨
    
    å‚æ•°:
        conversion_matrix: 4Ã—5è½¬æ¢çŸ©é˜µ
    
    è¿”å›:
        çŸ©é˜µæ€§è´¨åˆ†æç»“æœ
    """
    properties = {
        'matrix_analysis': {},
        'numerical_stability': {},
        'physical_constraints': {}
    }
    
    # çŸ©é˜µåˆ†æ
    matrix_rank = np.linalg.matrix_rank(conversion_matrix)
    condition_number = np.linalg.cond(conversion_matrix[:, :4])  # å–4Ã—4å­çŸ©é˜µ
    
    properties['matrix_analysis'] = {
        'matrix_rank': matrix_rank,
        'condition_number': condition_number,
        'determinant': np.linalg.det(conversion_matrix[:, :4]),
        'frobenius_norm': np.linalg.norm(conversion_matrix, 'fro')
    }
    
    # æ•°å€¼ç¨³å®šæ€§
    eigenvalues = np.linalg.eigvals(conversion_matrix[:, :4])
    properties['numerical_stability'] = {
        'eigenvalues': eigenvalues.tolist(),
        'spectral_radius': np.max(np.abs(eigenvalues)),
        'stability_indicator': np.all(np.abs(eigenvalues) < 2.0)
    }
    
    # ç‰©ç†çº¦æŸæ£€æŸ¥
    non_negative_ratio = np.sum(conversion_matrix >= 0) / conversion_matrix.size
    reasonable_range_ratio = np.sum((conversion_matrix >= 0) & (conversion_matrix <= 1.5)) / conversion_matrix.size
    
    properties['physical_constraints'] = {
        'non_negative_ratio': non_negative_ratio,
        'reasonable_range_ratio': reasonable_range_ratio,
        'energy_conservation': np.sum(conversion_matrix, axis=1).tolist(),
        'physical_validity': non_negative_ratio > 0.8 and reasonable_range_ratio > 0.9
    }
    
    return properties

def generate_optimization_report(converter_results):
    """
    ç”Ÿæˆå®Œæ•´çš„ä¼˜åŒ–æŠ¥å‘Š
    
    å‚æ•°:
        converter_results: è½¬æ¢å™¨å®Œæ•´ç»“æœ
    
    è¿”å›:
        æ ¼å¼åŒ–çš„ä¼˜åŒ–æŠ¥å‘Š
    """
    if not converter_results:
        return "ä¼˜åŒ–å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š"
    
    report_lines = []
    report_lines.append("=" * 60)
    report_lines.append("PSOä¼˜åŒ–4é€šé“åˆ°5é€šé“é¢œè‰²è½¬æ¢ - æ€§èƒ½æŠ¥å‘Š")
    report_lines.append("=" * 60)
    
    # åŸºæœ¬ä¿¡æ¯
    report_lines.append(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
    report_lines.append(f"   æœ€ä¼˜é€‚åº”åº¦: {converter_results['best_fitness']:.4f}")
    report_lines.append(f"   ä¼˜åŒ–å‚æ•°ç»´åº¦: 29ç»´")
    report_lines.append(f"   è½¬æ¢çŸ©é˜µè§„æ¨¡: 4Ã—5")
    
    # è´¨é‡è¯„ä¼°
    evaluation = converter_results['evaluation']
    report_lines.append(f"\nğŸ¯ è½¬æ¢è´¨é‡:")
    report_lines.append(f"   å¹³å‡è‰²å·®Î”E: {evaluation['mean_delta_e']:.4f}")
    report_lines.append(f"   ä¼˜ç§€çº§åˆ«æ¯”ä¾‹: {evaluation['excellent_ratio']:.2%}")
    report_lines.append(f"   è‰¯å¥½çº§åˆ«æ¯”ä¾‹: {evaluation['good_ratio']:.2%}")
    report_lines.append(f"   å¯æ¥å—æ¯”ä¾‹: {evaluation['acceptable_ratio']:.2%}")
    
    # æ€§èƒ½ç­‰çº§
    excellent_ratio = evaluation['excellent_ratio']
    if excellent_ratio >= 0.8:
        grade = "A+ (å“è¶Š)"
    elif excellent_ratio >= 0.6:
        grade = "A (ä¼˜ç§€)"
    elif excellent_ratio >= 0.4:
        grade = "B (è‰¯å¥½)"
    else:
        grade = "C (éœ€æ”¹è¿›)"
    
    report_lines.append(f"\nâ­ æ•´ä½“è¯„çº§: {grade}")
    
    # æ”¶æ•›åˆ†æ
    history = converter_results['optimization_history']
    if history:
        improvement = (history[0] - history[-1]) / history[0] * 100
        report_lines.append(f"\nğŸ“ˆ æ”¶æ•›æ€§èƒ½:")
        report_lines.append(f"   é€‚åº”åº¦æ”¹å–„: {improvement:.1f}%")
        report_lines.append(f"   è¿­ä»£æ¬¡æ•°: {len(history)}")
        report_lines.append(f"   æ”¶æ•›ç¨³å®šæ€§: {'ç¨³å®š' if np.std(history[-10:]) < 0.1 else 'éœ€ä¼˜åŒ–'}")
    
    # çŸ©é˜µæ€§è´¨
    matrix_props = calculate_conversion_matrix_properties(converter_results['conversion_matrix'])
    report_lines.append(f"\nğŸ”§ è½¬æ¢çŸ©é˜µ:")
    report_lines.append(f"   æ•°å€¼ç¨³å®šæ€§: {'è‰¯å¥½' if matrix_props['numerical_stability']['stability_indicator'] else 'éœ€æ³¨æ„'}")
    report_lines.append(f"   ç‰©ç†æœ‰æ•ˆæ€§: {'æœ‰æ•ˆ' if matrix_props['physical_constraints']['physical_validity'] else 'éœ€æ£€æŸ¥'}")
    
    report_lines.append(f"\n" + "=" * 60)
    
    return "\n".join(report_lines)
```
